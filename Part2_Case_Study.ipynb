# Part2_Case_Study.ipynb
# Hospital readmission risk prediction case study

# =========================
# Import Libraries
# =========================
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report

# =========================
# 1. Problem Scope
# =========================
# Problem: Predict 30-day patient readmission risk
# Objectives:
# 1. Identify high-risk patients
# 2. Reduce avoidable readmissions
# 3. Optimize hospital resource allocation
# Stakeholders:
# 1. Hospital management
# 2. Physicians/care coordinators

# =========================
# 2. Data Strategy
# =========================
# Hypothetical dataset creation
df = pd.DataFrame({
    'Age': [65, 50, 72, 33, 40, 58, 61, 29],
    'Num_prior_admissions': [2, 0, 3, 1, 0, 2, 1, 0],
    'Comorbidity_score': [3, 1, 4, 2, 1, 3, 2, 0],
    'Discharge_type': ['Home', 'Home', 'Rehab', 'Home', 'Home', 'Home', 'Rehab', 'Home'],
    'Readmit_30days': [1, 0, 1, 0, 0, 1, 1, 0]
})

# Preprocessing Pipeline
# 1. Impute missing numeric values (not needed here, but included for generality)
numeric_cols = ['Age', 'Num_prior_admissions', 'Comorbidity_score']
imputer = SimpleImputer(strategy='median')
df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

# 2. Normalize numeric features
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# 3. Encode categorical variables
df = pd.get_dummies(df, columns=['Discharge_type'])

print("Preprocessed Data:")
print(df)

# =========================
# 3. Model Development
# =========================
X = df.drop('Readmit_30days', axis=1)
y = df['Readmit_30days']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Model choice: XGBoost
model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Precision and Recall
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

# =========================
# 4. Deployment Notes
# =========================
# Integration: Export model as API (Flask/FastAPI) → Integrate with EHR system → Dashboard for clinicians
# Compliance: Encrypt data, access control, HIPAA compliance

# =========================
# 5. Optimization
# =========================
# Address overfitting using:
# - Cross-validation
# - Early stopping
